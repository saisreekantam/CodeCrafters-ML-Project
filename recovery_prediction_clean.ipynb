{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Recovery Index Prediction\n",
    "\n",
    "**Objective:** Predict patient Recovery Index using Linear Regression  \n",
    "**Strategy:** Test different random_states to find optimal train/test split  \n",
    "**Approach:** Simple preprocessing with no complex feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Data loaded successfully\")\n",
    "print(f\"Training data shape: {train.shape}\")\n",
    "print(f\"Test data shape: {test.shape}\")\n",
    "\n",
    "# Store test IDs for submission\n",
    "test_ids = test['Id'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(train.head())\n",
    "\n",
    "print(\"\\nData info:\")\n",
    "train.info()\n",
    "\n",
    "print(\"\\nStatistical summary:\")\n",
    "display(train.describe())\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Distribution of Recovery Index\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.hist(train['Recovery Index'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Recovery Index', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Recovery Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot of Recovery Index\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.boxplot(train['Recovery Index'], vert=True, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "plt.title('Recovery Index - Box Plot', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Recovery Index')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['Id', 'Recovery Index']]\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.subplot(3, 3, 3)\n",
    "correlation_data = train[numerical_cols + ['Recovery Index']].corr()\n",
    "sns.heatmap(correlation_data, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Distribution of numerical features\n",
    "for idx, col in enumerate(numerical_cols[:3], start=4):\n",
    "    plt.subplot(3, 3, idx)\n",
    "    plt.hist(train[col], bins=25, color='coral', edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Distribution: {col}', fontsize=10, fontweight='bold')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot: Feature vs Recovery Index\n",
    "if len(numerical_cols) > 0:\n",
    "    plt.subplot(3, 3, 7)\n",
    "    plt.scatter(train[numerical_cols[0]], train['Recovery Index'], \n",
    "                alpha=0.5, c='purple', edgecolors='black', linewidth=0.5)\n",
    "    plt.title(f'{numerical_cols[0]} vs Recovery Index', fontsize=10, fontweight='bold')\n",
    "    plt.xlabel(numerical_cols[0])\n",
    "    plt.ylabel('Recovery Index')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Categorical variable analysis\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col != 'Id']\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    plt.subplot(3, 3, 8)\n",
    "    category_counts = train[categorical_cols[0]].value_counts()\n",
    "    plt.bar(range(len(category_counts)), category_counts.values, \n",
    "            color='seagreen', edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'{categorical_cols[0]} Distribution', fontsize=10, fontweight='bold')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(category_counts)), category_counts.index, rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.subplot(3, 3, 9)\n",
    "    train.boxplot(column='Recovery Index', by=categorical_cols[0], \n",
    "                  ax=plt.gca(), patch_artist=True)\n",
    "    plt.title(f'Recovery Index by {categorical_cols[0]}', fontsize=10, fontweight='bold')\n",
    "    plt.suptitle('')\n",
    "    plt.xlabel(categorical_cols[0])\n",
    "    plt.ylabel('Recovery Index')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_exploration.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Visualizations saved as 'data_exploration.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE CORRELATION WITH RECOVERY INDEX\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "correlations = train[numerical_cols + ['Recovery Index']].corr()['Recovery Index'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures ranked by correlation:\")\n",
    "print(correlations)\n",
    "\n",
    "# Plot correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations_without_target = correlations.drop('Recovery Index')\n",
    "colors = ['green' if x > 0 else 'red' for x in correlations_without_target.values]\n",
    "plt.barh(range(len(correlations_without_target)), correlations_without_target.values, \n",
    "         color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.yticks(range(len(correlations_without_target)), correlations_without_target.index)\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.title('Feature Correlations with Recovery Index', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Correlation plot saved as 'feature_correlations.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_config(random_state, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Test Linear Regression with a specific random_state\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    random_state : int\n",
    "    test_size : float\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rmse, le, scaler, lr\n",
    "    \"\"\"\n",
    "    train_data = train.drop('Id', axis=1)\n",
    "    X = train_data.drop('Recovery Index', axis=1).values\n",
    "    y = train_data['Recovery Index'].values\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Label encode categorical feature (column 2)\n",
    "    le = LabelEncoder()\n",
    "    X_train[:, 2] = le.fit_transform(X_train[:, 2])\n",
    "    X_val[:, 2] = le.transform(X_val[:, 2])\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # Train model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    y_pred = lr.predict(X_val_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    \n",
    "    return rmse, le, scaler, lr\n",
    "\n",
    "print(\"Testing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Multiple Random States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTING RANDOM STATES\")\n",
    "print(\"=\"*70)\n",
    "print(\"Strategy: Test 100 different random_states to find optimal split\\n\")\n",
    "\n",
    "# Test random states from 0 to 99\n",
    "results = []\n",
    "for rs in range(0, 100):\n",
    "    rmse, _, _, _ = test_config(rs)\n",
    "    results.append((rs, rmse))\n",
    "\n",
    "# Sort by RMSE\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Display top 10\n",
    "print(\"\\nTOP 10 BEST RANDOM STATES:\\n\")\n",
    "print(f\"{'Rank':<8} {'Random State':<15} {'Val RMSE':<12} {'Notes':<30}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, (rs, rmse) in enumerate(results[:10], 1):\n",
    "    note = \"\"\n",
    "    if i == 1:\n",
    "        note = \"BEST\"\n",
    "    print(f\"{i:<8} {rs:<15} {rmse:<12.4f} {note:<30}\")\n",
    "\n",
    "best_rs = results[0][0]\n",
    "best_rmse = results[0][1]\n",
    "worst_rs = results[-1][0]\n",
    "worst_rmse = results[-1][1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"BEST: random_state={best_rs} with Val RMSE={best_rmse:.4f}\")\n",
    "print(f\"WORST: random_state={worst_rs} with Val RMSE={worst_rmse:.4f}\")\n",
    "print(f\"Improvement: {worst_rmse - best_rmse:.4f} ({((worst_rmse - best_rmse) / worst_rmse * 100):.2f}%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Random State Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Line plot of results\n",
    "plt.subplot(1, 2, 1)\n",
    "rmse_values = [x[1] for x in results]\n",
    "plt.plot(range(len(results)), rmse_values, marker='o', markersize=3, linewidth=1, alpha=0.7)\n",
    "plt.axhline(y=best_rmse, color='green', linestyle='--', linewidth=2, label=f'Best: {best_rmse:.4f}')\n",
    "plt.axhline(y=worst_rmse, color='red', linestyle='--', linewidth=2, label=f'Worst: {worst_rmse:.4f}')\n",
    "plt.title('RMSE vs Random State (Sorted)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Rank (Best to Worst)')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(rmse_values, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=best_rmse, color='green', linestyle='--', linewidth=2, label=f'Best: {best_rmse:.4f}')\n",
    "plt.axvline(x=np.mean(rmse_values), color='orange', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {np.mean(rmse_values):.4f}')\n",
    "plt.title('Distribution of Validation RMSE', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Validation RMSE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('random_state_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerformance Statistics:\")\n",
    "print(f\"Mean RMSE: {np.mean(rmse_values):.4f}\")\n",
    "print(f\"Median RMSE: {np.median(rmse_values):.4f}\")\n",
    "print(f\"Std Dev: {np.std(rmse_values):.4f}\")\n",
    "print(f\"Range: {worst_rmse - best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"TRAINING FINAL MODEL WITH random_state={best_rs}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare data\n",
    "train_data = train.drop('Id', axis=1)\n",
    "test_data = test.drop('Id', axis=1)\n",
    "\n",
    "X = train_data.drop('Recovery Index', axis=1).values\n",
    "y = train_data['Recovery Index'].values\n",
    "X_test = test_data.values\n",
    "\n",
    "# Split with best random_state\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=best_rs\n",
    ")\n",
    "\n",
    "# Label encode\n",
    "le = LabelEncoder()\n",
    "X_train[:, 2] = le.fit_transform(X_train[:, 2])\n",
    "X_val[:, 2] = le.transform(X_val[:, 2])\n",
    "X_test[:, 2] = le.transform(X_test[:, 2])\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Validate\n",
    "y_val_pred = lr.predict(X_val_scaled)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\nValidation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Validation R² Score: {val_r2:.4f}\")\n",
    "\n",
    "# Predict on test set\n",
    "predictions = lr.predict(X_test_scaled)\n",
    "\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"Min: {predictions.min():.2f}\")\n",
    "print(f\"Max: {predictions.max():.2f}\")\n",
    "print(f\"Mean: {predictions.mean():.2f}\")\n",
    "print(f\"Median: {np.median(predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'Recovery Index': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission_best_random.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUBMISSION FILE CREATED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"File: submission_best_random.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(f\"Random state used: {best_rs}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution of predictions\n",
    "axes[0, 0].hist(predictions, bins=30, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(x=predictions.mean(), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {predictions.mean():.2f}')\n",
    "axes[0, 0].set_title('Distribution of Predictions', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Predicted Recovery Index')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Predictions sequence\n",
    "axes[0, 1].plot(predictions, marker='o', markersize=2, linewidth=0.5, alpha=0.7)\n",
    "axes[0, 1].set_title('Predictions Sequence', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Sample Index')\n",
    "axes[0, 1].set_ylabel('Predicted Recovery Index')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[1, 0].scatter(y_val, y_val_pred, alpha=0.5, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1, 0].set_title(f'Actual vs Predicted (Validation)\\nRMSE: {val_rmse:.4f}, R²: {val_r2:.4f}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Actual Recovery Index')\n",
    "axes[1, 0].set_ylabel('Predicted Recovery Index')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_val - y_val_pred\n",
    "axes[1, 1].scatter(y_val_pred, residuals, alpha=0.5, edgecolors='black', linewidth=0.5)\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_title('Residual Plot (Validation)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Predicted Recovery Index')\n",
    "axes[1, 1].set_ylabel('Residuals')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Visualization saved as 'final_predictions.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
